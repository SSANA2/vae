{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabe637a-e6d7-42e5-aafa-88baa4d901c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa42eec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b2fa1a-1d13-464e-9da8-e9b317027e66",
   "metadata": {},
   "source": [
    "# CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70f808-1302-43c9-baec-466470dd8637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d1aa1b-8260-4910-9748-8a2ccf654b9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from configs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391ed6bb-6479-44f2-a09d-f261aec341e5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46946d01-d1ef-4a0c-bb4d-698a3ad04a2a",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c607dd2f-0e14-4482-865a-1b2b1ca8b510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms = transforms.Compose([\n",
    "    transforms.Resize(size=(resize_h, resize_w)),\n",
    "    transforms.ToTensor(),    \n",
    "])\n",
    "dataset = CustomDataset(dataset_name=dataset_name, transforms=transforms)\n",
    "train_loader = dataset.get_dataloader(is_train=True,\n",
    "                                      batch_size=batch_size,\n",
    "                                      shuffle=True,\n",
    "                                      num_workers=num_workers,\n",
    "                                      prefetch_factor=prefetch_factor)\n",
    "test_loader = dataset.get_dataloader(is_train=False,\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=num_workers,\n",
    "                                     prefetch_factor=prefetch_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aceddd65-80dc-4696-82a8-8927030b04cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch is using cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('PyTorch is using', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2728646-498b-4a4e-b117-10d4f371daf5",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e42ca2a0-3f88-4a8c-b1f5-e41ca0def804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): GELU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): GELU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (10): GELU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (13): GELU()\n",
      "    (14): Dropout(p=0.1, inplace=False)\n",
      "    (15): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (16): GELU()\n",
      "    (17): Dropout(p=0.1, inplace=False)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (z_mu): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (z_logvar): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=20480, bias=True)\n",
      "    (1): Unflatten(dim=1, unflattened_size=(1024, 4, 5))\n",
      "    (2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): GELU()\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): GELU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): GELU()\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "    (11): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (12): GELU()\n",
      "    (13): Dropout(p=0.1, inplace=False)\n",
      "    (14): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (15): GELU()\n",
      "    (16): Dropout(p=0.1, inplace=False)\n",
      "    (17): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (18): GELU()\n",
      "    (19): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): GELU()\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (7): GELU()\n",
      "    (8): Dropout(p=0.1, inplace=False)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (10): GELU()\n",
      "    (11): Dropout(p=0.1, inplace=False)\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (13): GELU()\n",
      "    (14): Dropout(p=0.1, inplace=False)\n",
      "    (15): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (16): GELU()\n",
      "    (17): Dropout(p=0.1, inplace=False)\n",
      "    (18): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      "  (z_mu): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (z_logvar): Linear(in_features=20480, out_features=1024, bias=True)\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=20480, bias=True)\n",
      "    (1): Unflatten(dim=1, unflattened_size=(1024, 4, 5))\n",
      "    (2): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): GELU()\n",
      "    (4): Dropout(p=0.1, inplace=False)\n",
      "    (5): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): GELU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): GELU()\n",
      "    (10): Dropout(p=0.1, inplace=False)\n",
      "    (11): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (12): GELU()\n",
      "    (13): Dropout(p=0.1, inplace=False)\n",
      "    (14): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (15): GELU()\n",
      "    (16): Dropout(p=0.1, inplace=False)\n",
      "    (17): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (18): GELU()\n",
      "    (19): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (discriminator): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = resize_h, resize_w, input_ch\n",
    "model = AAE(input_dim, channels, num_z).to(device)\n",
    "print(model)\n",
    "discriminator = Discriminator(input_dim, channels, num_z).to(device)\n",
    "print(discriminator)\n",
    "optimizer_G = optim.Adam(model.parameters(), lr=init_lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr = init_lr)\n",
    "\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "#                                         lr_lambda=lambda epoch: lr_decay ** epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d08857-f922-4e84-9ec5-b091585c1dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "adversarial_loss = torch.nn.BCELoss()\n",
    "pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "# Learn\n",
    "total_time = 0\n",
    "# train_losses = {\"Generator loss\": []}\n",
    "# test_losses = {\"Generator loss\": [], \"Discriminator loss\":[]}\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "        \n",
    "\n",
    "        '''Train Generator'''\n",
    "        start_time = time.time()\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        mu,logvar = model.encode(real_imgs)\n",
    "        encoded_imgs = model.reparameterize(mu, logvar)\n",
    "        decoded_imgs = model.decode(encoded_imgs)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = 0.001 * adversarial_loss(discriminator(encoded_imgs), valid) + 0.999 * pixelwise_loss(\n",
    "            decoded_imgs, real_imgs\n",
    "        )\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        '''Train Discriminator'''\n",
    "        optimizer_D.zero_grad()\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], num_z))))\n",
    "\n",
    "        real_loss = adversarial_loss(discriminator(z), valid)\n",
    "        fake_loss = adversarial_loss(discriminator(encoded_imgs.detach()), fake)\n",
    "        d_loss = 0.5 * (real_loss + fake_loss)\n",
    "        \n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        dt = end_time - start_time\n",
    "        total_time += dt\n",
    "    print(f'Epoch {epoch} / {epochs} in {dt:.2f} secs')\n",
    "    print(f'Generator loss {g_loss.item():.4f}, Discriminator loss {d_loss.item():.4f}')\n",
    "    # generate and visualize\n",
    "    samples, recons = reconstruct(model, test_loader, device)\n",
    "    visualize_imgs(samples, recons)\n",
    "# print('Train loss[ELBO]:', train_losses[\"ELBO\"])\n",
    "# print('Test loss[Generator loss]:', g_loss.item())\n",
    "# print('Test loss[MSE]:', test_losses[\"MSE\"])\n",
    "print(f'Average {total_time / epochs:.2f} secs per epoch consumed')\n",
    "print(f'Total {total_time:.2f} secs consumed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d70454d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138f9ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
